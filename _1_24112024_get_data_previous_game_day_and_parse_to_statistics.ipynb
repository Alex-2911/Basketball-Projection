{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alex-2911/Basketball-Projection/blob/main/_1_24112024_get_data_previous_game_day_and_parse_to_statistics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "# !dpkg -i google-chrome-stable_current_amd64.deb\n",
        "# !apt-get -f install -y\n",
        "\n",
        "# !wget https://chromedriver.storage.googleapis.com/$(curl -sS https://chromedriver.storage.googleapis.com/LATEST_RELEASE)/chromedriver_linux64.zip\n",
        "# !unzip chromedriver_linux64.zip\n",
        "# !mv chromedriver /usr/bin/chromedriver\n",
        "# !chmod +x /usr/bin/chromedriver\n"
      ],
      "metadata": {
        "id": "yKp2_f-fs52V"
      },
      "id": "yKp2_f-fs52V",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import calendar\n",
        "import datetime\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "current_season = 2025\n",
        "\n",
        "#today = datetime.now()\n",
        "today = datetime.now() - timedelta(days=0)\n",
        "print(today)\n",
        "yesterday = datetime.now() - timedelta(days=1)\n",
        "\n",
        "\n",
        "import datetime\n",
        "#today_str_format = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "today_str_format = today.strftime(\"%Y-%m-%d\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfPBfd4FlJnI",
        "outputId": "b29f3638-c6c2-472a-b5d9-fef98e15b526"
      },
      "id": "wfPBfd4FlJnI",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-01 19:20:23.470806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get today's date\n",
        "# Determine the current and next month/year\n",
        "\n",
        "if today.day == 1:\n",
        "    current_month = today.month - 1\n",
        "\n",
        "    if current_month == 0:\n",
        "        current_month = 12\n",
        "        current_year = today.year - 1\n",
        "        last_month = 12\n",
        "        last_month_name = calendar.month_name[last_month].lower()\n",
        "    else:\n",
        "        current_year = today.year\n",
        "        last_month = current_month# - 1\n",
        "        last_month_name = calendar.month_name[last_month].lower()\n",
        "        print(last_month)\n",
        "else:\n",
        "    current_month = today.month\n",
        "    current_year = today.year\n",
        "    last_month = None  # Not used in this case"
      ],
      "metadata": {
        "id": "eRTDMt_elNQk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80955d50-0e2b-4849-d8fb-cf95ffef0aa0"
      },
      "id": "eRTDMt_elNQk",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define base directory in Google Drive\n",
        "#DATA_DIR = os.path.join(\"/content/drive/My Drive\", \"NBA_Script\", \"2025\", \"Gathering_Data\", \"data\")\n",
        "#SRC_DIR = os.path.join(\"/content/drive/My Drive\", \"NBA_Script\", \"2025\", \"Gathering_Data\", \"Whole_Statistic\")\n",
        "\n",
        "# Define directories\n",
        "base_dir = \"/content/drive/My Drive/NBA_Script/2025/Gathering_Data\"\n",
        "STANDINGS_DIR = os.path.join(base_dir, f\"{current_season}_standings\")\n",
        "SCORES_DIR = os.path.join(base_dir, f\"{current_season}_scores\")\n",
        "SRC_DIR = os.path.join(base_dir, f\"Whole_Statistic\")\n",
        "\n",
        "\n",
        "# Define subdirectories\n",
        "#STANDINGS_DIR = os.path.join(DATA_DIR, f\"{current_season}_standings\")\n",
        "#SCORES_DIR = os.path.join(DATA_DIR, f\"{current_season}_scores\") #Fixed: Removed the extra 'S' and uncommented the line\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(STANDINGS_DIR, exist_ok=True)\n",
        "os.makedirs(SCORES_DIR, exist_ok=True)\n",
        "\n",
        "#print(f\"Data Directory: {DATA_DIR}\") #Fixed: DATA_DIR is commented out above and not defined, causing a NameError\n",
        "print(f\"Standings Directory: {STANDINGS_DIR}\")\n",
        "print(f\"Scores Directory: {SCORES_DIR}\")\n",
        "print(f\"Whole_Statistic Directory: {SRC_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz4ymPs5lkwQ",
        "outputId": "5e7524e7-10e1-44fa-d533-5048987142ff"
      },
      "id": "Uz4ymPs5lkwQ",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Standings Directory: /content/drive/My Drive/NBA_Script/2025/Gathering_Data/2025_standings\n",
            "Scores Directory: /content/drive/My Drive/NBA_Script/2025/Gathering_Data/2025_scores\n",
            "Whole_Statistic Directory: /content/drive/My Drive/NBA_Script/2025/Gathering_Data/Whole_Statistic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_current_year_and_month():\n",
        "    \"\"\"\n",
        "    Returns the current year and month.\n",
        "    \"\"\"\n",
        "    today = datetime.now()\n",
        "    return today.year, today.month"
      ],
      "metadata": {
        "id": "lmXF02SGwIwP"
      },
      "id": "lmXF02SGwIwP",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium webdriver_manager\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.common.exceptions import TimeoutException, WebDriverException\n",
        "import os\n",
        "import logging\n",
        "import time\n",
        "\n",
        "# Configure logging\n",
        "# Initialize chrome_options before using it\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--disable-ipv6\")\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "def get_html(url, selector, sleep=5, retries=3, headless=True):\n",
        "    \"\"\"\n",
        "    Retrieves HTML content from a webpage using Selenium WebDriver.\n",
        "    \"\"\"\n",
        "    html = None\n",
        "    # Initialize driver to None outside the loop\n",
        "    driver = None\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            # WebDriver options\n",
        "            # chrome_options is now defined globally\n",
        "            if headless:\n",
        "                chrome_options.add_argument(\"--headless\")\n",
        "                chrome_options.add_argument(\"--no-sandbox\")\n",
        "                chrome_options.add_argument(\"--disable-dev-shm-usage\")  # Overcome limited resource issues\n",
        "\n",
        "            # Use ChromeDriverManager to manage the driver\n",
        "            service = Service(ChromeDriverManager().install())\n",
        "            driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "\n",
        "            driver.get(url)\n",
        "            time.sleep(sleep * (2 ** attempt))  # Exponential backoff\n",
        "            element = driver.find_element(By.CSS_SELECTOR, selector)\n",
        "            html = element.get_attribute(\"innerHTML\")\n",
        "\n",
        "            driver.quit() # Quit the driver after successful retrieval\n",
        "            break # Exit the retry loop if successful\n",
        "\n",
        "        except TimeoutException:\n",
        "            logging.warning(f\"Attempt {attempt + 1}: Timeout error on {url}. Retrying...\")\n",
        "            if driver is not None: # Now driver is defined before this line\n",
        "              driver.quit() #Quit the driver before retrying\n",
        "        except WebDriverException as e:\n",
        "            logging.error(f\"Webdriver error: {e}\")\n",
        "            if driver is not None: # Now driver is defined before this line\n",
        "              driver.quit() #Quit the driver if any WebDriverException occurs\n",
        "            break # Exit the loop if there's a WebDriverException\n",
        "\n",
        "    if html is None:\n",
        "        logging.error(f\"Failed to retrieve HTML content from {url} after {retries} attempts.\")\n",
        "\n",
        "    return html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb5obV5G91Kk",
        "outputId": "26f7cb98-b8d4-4f54-8b00-ec833e66fb85"
      },
      "id": "pb5obV5G91Kk",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (4.27.1)\n",
            "Requirement already satisfied: webdriver_manager in /usr/local/lib/python3.10/dist-packages (4.0.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.27.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.8.30)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from webdriver_manager) (2.32.3)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from webdriver_manager) (1.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from webdriver_manager) (24.2)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (24.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver_manager) (3.4.0)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_season_for_month(season, month, month_name, standings_dir, get_html_function):\n",
        "    \"\"\"\n",
        "    Scrapes NBA games data for a specific month and season from basketball-reference.com.\n",
        "\n",
        "    Args:\n",
        "        season (int): The NBA season year.\n",
        "        month (int): The month number (1-12).\n",
        "        month_name (str): The name of the month.\n",
        "        standings_dir (str): Directory path to save the scraped data.\n",
        "        get_html_function (function): Function to get HTML content from a URL.\n",
        "    \"\"\"\n",
        "    #current_year, current_month = get_current_year_and_month()\n",
        "\n",
        "    if season < current_year or (season == current_year and month < current_month):\n",
        "        logging.warning(\"Invalid year or month already passed.\")\n",
        "        return\n",
        "\n",
        "    logging.info(f\"Scraping games for: {season}, {month_name.title()}\")\n",
        "    url = f\"https://www.basketball-reference.com/leagues/NBA_{season}_games.html\"\n",
        "    selector = \"#content .filter\"\n",
        "    html_content = get_html_function(url, selector)\n",
        "\n",
        "    if not html_content:\n",
        "        logging.error(f\"Failed to retrieve data from {url}.\")\n",
        "        return\n",
        "\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    links = soup.find_all(\"a\", href=re.compile(\"/leagues/NBA_[0-9]{4}_games-[a-z]+\\.html\"))\n",
        "    standings_pages = [f\"https://www.basketball-reference.com{l['href']}\" for l in links]\n",
        "\n",
        "    for url in standings_pages:\n",
        "        save_path = os.path.join(standings_dir, url.split(\"/\")[-1])\n",
        "        if os.path.exists(save_path):\n",
        "            logging.info(f\"Path already exists: {save_path}\")\n",
        "            continue\n",
        "\n",
        "        if month_name in save_path.lower():\n",
        "            html = get_html_function(url, \"#all_schedule\")\n",
        "            #print(html)\n",
        "            if html:\n",
        "                try:\n",
        "                    with open(save_path, \"w+\", encoding='utf-8') as f:\n",
        "                        f.write(html)\n",
        "                    logging.info(f\"Data for {month_name.title()} saved.\")\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"Failed to save data for {month_name.title()}: {e}\")\n",
        "            else:\n",
        "                logging.error(f\"Failed to retrieve data for {month_name.title()} from {url}.\")\n",
        "\n",
        "# Usage example:\n",
        "# season = 2024\n",
        "# month = 1\n",
        "# standings_dir = \"path/to/standings_dir\"\n",
        "# scrape_monthly_games(season, month, standings_dir, get_html)\n"
      ],
      "metadata": {
        "id": "Wcqb-8kKmEXy"
      },
      "id": "Wcqb-8kKmEXy",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !apt-get update\n",
        "# !apt install chromium-chromedriver\n",
        "# !cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ],
      "metadata": {
        "id": "1tfvLR7_u6b8"
      },
      "id": "1tfvLR7_u6b8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install selenium\n",
        "# from selenium import webdriver\n",
        "# from selenium.webdriver.chrome.options import Options\n",
        "# from selenium.webdriver.chrome.service import Service\n",
        "# from selenium.webdriver.common.by import By\n",
        "# from selenium.common.exceptions import TimeoutException, WebDriverException"
      ],
      "metadata": {
        "id": "phmsMFedvMdb"
      },
      "id": "phmsMFedvMdb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def initialize_driver():\n",
        "#     chrome_options = Options()\n",
        "#     chrome_options.add_argument(\"--headless\")\n",
        "#     chrome_options.add_argument(\"--no-sandbox\")\n",
        "#     chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "#     service = Service(ChromeDriverManager().install())\n",
        "#     return webdriver.Chrome(service=service, options=chrome_options)\n"
      ],
      "metadata": {
        "id": "e4XiKTRKx2__"
      },
      "id": "e4XiKTRKx2__",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import calendar\n",
        "import logging\n",
        "from datetime import datetime\n",
        "\n",
        "#chromedriver_path = r\"D:\\1. Python\\3. chromedriver-win64\\chromedriver-win64\\chromedriver.exe\"\n",
        "\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Initialize variables\n",
        "current_season = 2025\n",
        "today = datetime.now()\n",
        "current_month = today.month\n",
        "current_year = today.year\n",
        "\n",
        "# Calculate next and last months\n",
        "next_month = current_month + 1 if current_month < 12 else 1\n",
        "next_year = current_year if next_month != 1 else current_year + 1\n",
        "last_month = current_month - 1 if current_month > 1 else 12\n",
        "last_year = current_year if last_month != 12 else current_year - 1\n",
        "\n",
        "# Month names\n",
        "current_month_name = calendar.month_name[current_month].lower()\n",
        "next_month_name = calendar.month_name[next_month].lower()\n",
        "last_month_name = calendar.month_name[last_month].lower()\n",
        "\n",
        "# Define directories\n",
        "#base_dir = \"/content/drive/My Drive/NBA_Script/2025/Gathering_Data\"\n",
        "#STANDINGS_DIR = os.path.join(base_dir, f\"{current_season}_standings\")\n",
        "#SCORES_DIR = os.path.join(base_dir, f\"{current_season}_scores\")\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(STANDINGS_DIR, exist_ok=True)\n",
        "os.makedirs(SCORES_DIR, exist_ok=True)\n",
        "\n",
        "# File removal logic\n",
        "# File removal logic\n",
        "if today.day == 1:  # Only delete previous month's file on the 1st\n",
        "    file_to_remove = f\"NBA_{current_season}_games-{last_month_name}.html\"  # Use last_month_name (november)\n",
        "    file_path = os.path.join(STANDINGS_DIR, file_to_remove)\n",
        "\n",
        "    try:\n",
        "        if os.path.exists(file_path):\n",
        "            os.remove(file_path)\n",
        "            logging.info(f\"File {file_to_remove} has been removed.\")\n",
        "        else:\n",
        "            logging.info(f\"File {file_to_remove} does not exist.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An error occurred while removing {file_to_remove}: {e}\")\n",
        "\n",
        "try:\n",
        "    if os.path.exists(file_path):\n",
        "        os.remove(file_path)\n",
        "        logging.info(f\"File {file_to_remove} has been removed.\")\n",
        "    else:\n",
        "        logging.info(f\"File {file_to_remove} does not exist.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"An error occurred while removing {file_to_remove}: {e}\")\n",
        "\n",
        "# WebDriver initialization\n",
        "#driver = initialize_driver()\n",
        "\n",
        "try:\n",
        "    # Scrape games for the appropriate months\n",
        "    if today.day == 1:\n",
        "        scrape_season_for_month(current_season, last_month, last_month_name, STANDINGS_DIR, get_html)\n",
        "        scrape_season_for_month(current_season, next_month, next_month_name, STANDINGS_DIR, get_html)\n",
        "    else:\n",
        "        scrape_season_for_month(current_season, current_month, current_month_name, STANDINGS_DIR, get_html)\n",
        "\n",
        "    # Example of processing game data (uncomment when functions are defined)\n",
        "    # standings_files = os.listdir(STANDINGS_DIR)\n",
        "    # for f in standings_files:\n",
        "    #     if str(current_year) in f:\n",
        "    #         filepath = os.path.join(STANDINGS_DIR, f)\n",
        "    #         scrape_game(filepath, SCORES_DIR, driver)\n",
        "\n",
        "finally:\n",
        "    #driver.quit()\n",
        "    logging.info(\"Driver session closed.\")\n"
      ],
      "metadata": {
        "id": "AKpeAmbkmKTs"
      },
      "id": "AKpeAmbkmKTs",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "\n",
        "def scrape_game(standings_file, scores_dir, get_html_function):\n",
        "    \"\"\"\n",
        "    Scrapes box scores for NBA games from the provided standings file.\n",
        "\n",
        "    Args:\n",
        "        standings_file (str): Path to the file containing the standings data.\n",
        "        scores_dir (str): Directory path to save the scraped box scores.\n",
        "        get_html_function (function): Function to get HTML content from a URL.\n",
        "    \"\"\"\n",
        "    # Calculate the date of yesterday\n",
        "    #yesterday = datetime.now() - timedelta(days=1)\n",
        "    yesterday_date = yesterday.strftime(\"%Y%m%d\")  # Format: YYYYMMDD\n",
        "\n",
        "    with open(standings_file, 'r',encoding='utf-8') as f:\n",
        "        html = f.read()\n",
        "\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    links = soup.find_all(\"a\")\n",
        "    hrefs = [l.get('href') for l in links]\n",
        "    box_scores = [f\"https://www.basketball-reference.com{l}\" for l in hrefs if l and \"boxscore\" in l and '.html' in l]\n",
        "\n",
        "    filtered_urls = [url for url in box_scores if yesterday_date in url]\n",
        "\n",
        "    for url in filtered_urls:\n",
        "        save_path = os.path.join(scores_dir, url.split(\"/\")[-1])\n",
        "\n",
        "        if os.path.exists(save_path):\n",
        "            continue\n",
        "\n",
        "        html = get_html_function(url, \"#content\")\n",
        "\n",
        "        if not html:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            with open(save_path, \"wb+\") as f:\n",
        "                f.write(html.encode(\"utf-8\"))\n",
        "            print(f\"Box score saved: {save_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to save box score: {e}\")\n"
      ],
      "metadata": {
        "id": "Y15qWqeU27xK"
      },
      "id": "Y15qWqeU27xK",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_standings_files(standings_dir, current_season):\n",
        "    \"\"\"\n",
        "    Process standings files for a specific season.\n",
        "\n",
        "    Args:\n",
        "        standings_dir (str): Directory containing standings files.\n",
        "        current_season (int): The current NBA season year.\n",
        "    \"\"\"\n",
        "    standings_files = os.listdir(standings_dir)\n",
        "    print(standings_files)\n",
        "\n",
        "    # Filter files for the current season\n",
        "    files = [s for s in standings_files if str(current_season) in s]\n",
        "\n",
        "    for f in files:\n",
        "        filepath = os.path.join(standings_dir, f)\n",
        "        print(filepath)\n",
        "\n",
        "        scrape_game(filepath, SCORES_DIR, get_html)  # Assuming scrape_game is implemented\n",
        "\n",
        "# Call the function with your STANDINGS_DIR and current_season\n",
        "process_standings_files(STANDINGS_DIR, current_season)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7yt3cHz2q13",
        "outputId": "e9ca0818-fc74-4916-b68a-dca06ae3d43f"
      },
      "id": "S7yt3cHz2q13",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NBA_2025_games-october.html', 'NBA_2025_games-january.html', 'NBA_2025_games-november.html']\n",
            "/content/drive/My Drive/NBA_Script/2025/Gathering_Data/2025_standings/NBA_2025_games-october.html\n",
            "/content/drive/My Drive/NBA_Script/2025/Gathering_Data/2025_standings/NBA_2025_games-january.html\n",
            "/content/drive/My Drive/NBA_Script/2025/Gathering_Data/2025_standings/NBA_2025_games-november.html\n",
            "Box score saved: /content/drive/My Drive/NBA_Script/2025/Gathering_Data/2025_scores/202411300CHO.html\n",
            "Box score saved: /content/drive/My Drive/NBA_Script/2025/Gathering_Data/2025_scores/202411300DET.html\n",
            "Box score saved: /content/drive/My Drive/NBA_Script/2025/Gathering_Data/2025_scores/202411300MIL.html\n",
            "Box score saved: /content/drive/My Drive/NBA_Script/2025/Gathering_Data/2025_scores/202411300PHO.html\n",
            "Box score saved: /content/drive/My Drive/NBA_Script/2025/Gathering_Data/2025_scores/202411300UTA.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def get_first_game_date(standings_file):\n",
        "    \"\"\"\n",
        "    Extract the date of the first game day from the standings file.\n",
        "\n",
        "    Args:\n",
        "        standings_file (str): Path to the standings HTML file.\n",
        "\n",
        "    Returns:\n",
        "        str: The date of the first game, formatted as 'Day, Month Date, Year'.\n",
        "    \"\"\"\n",
        "    with open(standings_file, 'r', encoding='utf-8') as f:\n",
        "        html = f.read()\n",
        "\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "    # Find the first game date in the standings table\n",
        "    table = soup.find(\"table\", {\"id\": \"schedule\"})\n",
        "\n",
        "    if not table:\n",
        "        print(f\"No schedule table found in {standings_file}.\")\n",
        "        return None\n",
        "\n",
        "    # Look for the first non-header row (actual game data)\n",
        "    first_game_row = table.find_all(\"tr\")[1]  # Skip the header row and take the first game row\n",
        "    if first_game_row:\n",
        "        game_date_tag = first_game_row.find(\"th\", {\"data-stat\": \"date_game\"})\n",
        "        if game_date_tag:\n",
        "            return game_date_tag.text.strip()  # Returns the date of the first game\n",
        "\n",
        "    return None\n",
        "\n",
        "# Example usage\n",
        "standings_file =  os.path.join(STANDINGS_DIR, 'NBA_2025_games-october.html')  # Replace with the actual path to your file\n",
        "\n",
        "first_game_date_str = get_first_game_date(standings_file)\n",
        "#if first_game_date_str:\n",
        "#    print(f\"The first game is scheduled on: {first_game_date_str}\")\n",
        "#else:\n",
        "#    print(\"No game dates found in the file.\")\n"
      ],
      "metadata": {
        "id": "VDYQFIqj36pY"
      },
      "id": "VDYQFIqj36pY",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import logging\n",
        "from io import StringIO\n",
        "import numpy as np\n",
        "\n",
        "MAX_DAYS_BACK = 150  # Configurable range for searching files\n",
        "\n",
        "# Constants\n",
        "#SCORE_DIR = \"data/2025_scores\"\n",
        "#SRC_DIR = r'D:\\1. Python\\1. NBA Script\\2025\\Gathering_Data\\Whole_Statistic'\n",
        "#DST_DIR = r'D:\\_Laufwerk C\\11. Sorare\\NBA\\2025\\Gathering_Data\\Whole_Statistic'\n",
        "\n",
        "# Assume first_game_date is already defined in your code\n",
        "\n",
        "first_game_date = datetime.datetime.strptime(first_game_date_str, \"%a, %b %d, %Y\").date()\n",
        "\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Check if the current date is before the season start date\n",
        "today = datetime.date.today()\n",
        "if today < first_game_date:\n",
        "    logging.info(f\"Current date ({today}) is before the NBA season start date ({first_game_date}). Script will not run.\")\n",
        "    exit()\n",
        "\n",
        "# If the script reaches here, it means the season has started, and we can proceed\n",
        "\n",
        "\n",
        "# Function to check if file exists\n",
        "def file_exists(date_str):\n",
        "    \"\"\"Check if a specific file exists based on the date string.\"\"\"\n",
        "    filename = f\"nba_games_{date_str}.csv\"\n",
        "    return os.path.isfile(os.path.join(SRC_DIR, filename))\n",
        "\n",
        "# Function to find the most recent file\n",
        "def find_most_recent_file(max_days=MAX_DAYS_BACK):\n",
        "    \"\"\"Find the most recent file within a specified number of days.\"\"\"\n",
        "    days_back = 1\n",
        "    while days_back <= max_days:\n",
        "        most_recent_date = (today - datetime.timedelta(days=days_back)).strftime(\"%Y-%m-%d\")\n",
        "        if file_exists(most_recent_date):\n",
        "            logging.info(f\"The file for {most_recent_date} exists.\")\n",
        "            return most_recent_date\n",
        "        else:\n",
        "            days_back += 1\n",
        "\n",
        "    logging.warning(\"No file found within the specified range.\")\n",
        "    return None\n",
        "\n",
        "# Main script execution\n",
        "try:\n",
        "    most_recent_date = find_most_recent_file()\n",
        "\n",
        "    if most_recent_date:\n",
        "        # Proceed with processing the found file\n",
        "        # Add your processing logic here\n",
        "        logging.info(f\"Processing file for {most_recent_date}\")\n",
        "    else:\n",
        "        # Handle the case when no file is found\n",
        "        logging.warning(\"No recent data available to process.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    logging.error(\"File or directory not found.\")\n",
        "except IOError:\n",
        "    logging.error(\"Error accessing file.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "\n",
        "# #########################################################################################################################\n",
        "# # CHECK FIRST IF THE SEASON HAS BEGUN AND THE DATA FROM PREVIOUS GAME DAY IS ACTUALLY AVAILABLE#\n",
        "# ##############################################################################################################"
      ],
      "metadata": {
        "id": "JQXUxrCh4U7U"
      },
      "id": "JQXUxrCh4U7U",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "today = datetime.date.today()\n",
        "if today < first_game_date:\n",
        "    logging.info(f\"Current date ({today}) is before the NBA season start date ({first_game_date}). Script will not run.\")\n",
        "    exit()\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Constants\n",
        "#SRC_DIR = r'D:\\1. Python\\1. NBA Script\\2025\\Gathering_Data\\Whole_Statistic'\n",
        "#SCORE_DIR = r'path_to_score_data'  # Define the path to score data\n",
        "\n",
        "# Functions\n",
        "def parse_html(box_score):\n",
        "    \"\"\"Parse HTML content from a box score file.\"\"\"\n",
        "    try:\n",
        "        with open(box_score, encoding='utf-8') as f:\n",
        "            html = f.read()\n",
        "        soup = BeautifulSoup(html, 'html.parser')\n",
        "        [s.decompose() for s in soup.select(\"tr.over_header, tr.thead\")]\n",
        "        return soup\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error parsing HTML for {box_score}: {e}\")\n",
        "        return None\n",
        "\n",
        "def read_season_info(soup):\n",
        "    \"\"\"Extract season information from the soup object.\"\"\"\n",
        "    nav = soup.select(\"#bottom_nav_container\")[0]\n",
        "    hrefs = [a[\"href\"] for a in nav.find_all('a')]\n",
        "    return os.path.basename(hrefs[1]).split(\"_\")[0]\n",
        "\n",
        "def read_line_score(soup):\n",
        "    \"\"\"Read line score from the soup object.\"\"\"\n",
        "    line_score = pd.read_html(StringIO(str(soup)), attrs={'id': 'line_score'})[0]\n",
        "    cols = list(line_score.columns)\n",
        "    cols[0] = \"team\"\n",
        "    cols[-1] = \"total\"\n",
        "    line_score.columns = cols\n",
        "    line_score = line_score[[\"team\", \"total\"]]\n",
        "    return line_score\n",
        "\n",
        "def read_stats(soup, team, stat):\n",
        "    \"\"\"Read team statistics from the soup object.\"\"\"\n",
        "    df = pd.read_html(StringIO(str(soup)), attrs={'id': f'box-{team}-game-{stat}'}, index_col=0)[0]\n",
        "    return df.apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "def copy_missing_files(src_dir, dst_dir):\n",
        "    \"\"\"Copy missing files from source to destination directory.\"\"\"\n",
        "    src_files = set(os.listdir(src_dir))\n",
        "    dst_files = set(os.listdir(dst_dir))\n",
        "    diff = src_files - dst_files\n",
        "\n",
        "    for file_name in diff:\n",
        "        if not file_name.startswith('.') and not file_name.endswith('.ipynb'):\n",
        "            shutil.copy2(os.path.join(src_dir, file_name), dst_dir)\n",
        "            logging.info(f'File {file_name} copied successfully')"
      ],
      "metadata": {
        "id": "y7zvj_Db6cjD"
      },
      "id": "y7zvj_Db6cjD",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Code\n",
        "# Main Code\n",
        "def process_nba_data():\n",
        "    \"\"\"Main function to process NBA data.\"\"\"\n",
        "    #last_file_date = (datetime.date.today() - datetime.timedelta(days=days_back)).strftime(\"%Y-%m-%d\")\n",
        "    last_file_date = most_recent_date\n",
        "    print(last_file_date)\n",
        "\n",
        "    filename = f\"nba_games_{last_file_date}.csv\"\n",
        "###########################################################################################################\n",
        "    try:\n",
        "        existing_statistics = pd.read_csv(os.path.join(SRC_DIR, filename))#, index_col=0)\n",
        "###########################################################################################################\n",
        "    except FileNotFoundError:\n",
        "        logging.error(f\"File {filename} not found in {SRC_DIR}.\")\n",
        "        return\n",
        "\n",
        "    base_cols = None\n",
        "    games = []\n",
        "\n",
        "    box_scores = [os.path.join(SCORES_DIR, f) for f in os.listdir(SCORES_DIR) if f.endswith(\".html\")]\n",
        "\n",
        "    # Check if box_scores is empty and log if it is\n",
        "    if not box_scores:\n",
        "        logging.warning(f\"No .html files found in {SCORES_DIR}. Check if the directory is correct and contains the necessary files.\")\n",
        "\n",
        "    # ... inside process_nba_data function ...\n",
        "    for box_score in box_scores:\n",
        "        try:\n",
        "            date = pd.Timestamp(os.path.basename(box_score)[:8]).date()\n",
        "\n",
        "            # Print the date being checked to help diagnose the issue\n",
        "            print(f\"Checking date: {date}, yesterday: {pd.Timestamp(yesterday).date()}\")\n",
        "\n",
        "            # Original condition:\n",
        "            # if date < pd.Timestamp(yesterday).date():\n",
        "            #     continue  # This line might be skipping all files\n",
        "\n",
        "            # Modified condition to only process files from yesterday or later\n",
        "            # Consider changing it if a different date range is required:\n",
        "            if date != pd.Timestamp(yesterday).date():\n",
        "                continue\n",
        "\n",
        "            # ... rest of the loop ...\n",
        "\n",
        "            # ... rest of the loop ...\n",
        "\n",
        "            soup = parse_html(box_score)\n",
        "            if soup is None:\n",
        "                continue\n",
        "\n",
        "            line_score = read_line_score(soup)\n",
        "            teams = list(line_score[\"team\"])\n",
        "            summaries = []\n",
        "\n",
        "            for team in teams:\n",
        "                basic = read_stats(soup, team, \"basic\")\n",
        "                advanced = read_stats(soup, team, \"advanced\")\n",
        "\n",
        "                totals = pd.concat([basic.iloc[-1], advanced.iloc[-1]])\n",
        "                totals.index = totals.index.str.lower()\n",
        "\n",
        "                maxes = pd.concat([basic.iloc[:-1].max(), advanced.iloc[:-1].max()])\n",
        "                maxes.index = maxes.index.str.lower() + \"_max\"\n",
        "\n",
        "                summary = pd.concat([totals, maxes])\n",
        "                if base_cols is None:\n",
        "                    base_cols = [b for b in summary.index.drop_duplicates(keep=\"first\") if \"bpm\" not in b]\n",
        "                summary = summary[base_cols]\n",
        "                summaries.append(summary)\n",
        "\n",
        "            summary = pd.concat(summaries, axis=1).T\n",
        "            game = pd.concat([summary, line_score], axis=1)\n",
        "            game[\"home\"] = [0, 1]\n",
        "\n",
        "            game_opp = game.iloc[::-1].reset_index()\n",
        "            game_opp.columns += \"_opp\"\n",
        "\n",
        "            full_game = pd.concat([game, game_opp], axis=1)\n",
        "\n",
        "            full_game[\"season\"] = read_season_info(soup)\n",
        "            full_game[\"date\"] = pd.Timestamp(os.path.basename(box_score)[:8])\n",
        "            full_game[\"won\"] = full_game[\"total\"] > full_game[\"total_opp\"]\n",
        "            games.append(full_game)\n",
        "\n",
        "            if len(games) % 100 == 0:\n",
        "                logging.info(f\"{len(games)} / {len(box_scores)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error processing {box_score}: {e}\")\n",
        "\n",
        "    games_df = pd.concat(games, ignore_index=True)\n",
        "    print(games_df.head(1).to_string(index=False))\n",
        "\n",
        "    # Ensure there are no duplicated columns in games_df\n",
        "    games_df = rename_duplicated_columns(games_df)\n",
        "\n",
        "    # Reindex games_df to match the columns of existing_statistics\n",
        "    games_df_reindexed = games_df.reindex(columns=existing_statistics.columns)\n",
        "\n",
        "    # Rename duplicated columns in games_df by appending a suffix\n",
        "    duplicated_columns = games_df.columns[games_df.columns.duplicated()]\n",
        "\n",
        "    for col in duplicated_columns:\n",
        "        count = 0\n",
        "        for i in range(len(games_df.columns)):\n",
        "            if games_df.columns[i] == col:\n",
        "                games_df.columns.values[i] = f\"{col}_{count}\"\n",
        "                count += 1\n",
        "\n",
        "\n",
        "    #print(existing_statistics.head(60).to_string(index=False))\n",
        "\n",
        "\n",
        "    file_name = f\"nba_games_{today}.csv\"\n",
        "    print(file_name)\n",
        "    #games_df.to_csv(\"nba_games.csv\")\n",
        "    #print(games_df.head(6).to_string(index=False))\n",
        "\n",
        "    #new_statistics = pd.read_csv(\"nba_games.csv\", index_col=0)\n",
        "    #print(new_statistics.head(60).to_string(index=False))\n",
        "\n",
        "    # if combined_statistics.shape[1] == existing_statistics.shape[1]:\n",
        "    #     print(\"Both DataFrames have the same number of columns.\")\n",
        "    # else:\n",
        "    #     print(f\"Different number of columns: combined_statistics has {combined_statistics.shape[1]}, existing_statistics has {existing_statistics.shape[1]}.\")\n",
        "\n",
        "    # Check and print duplicated columns for diagnosis\n",
        "    print(\"Existing Statistics Duplicated Columns:\", existing_statistics.columns[existing_statistics.columns.duplicated()])\n",
        "    print(\"Games DF Duplicated Columns:\", games_df.columns[games_df.columns.duplicated()])\n",
        "\n",
        "\n",
        "    existing_statistics.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    #print(existing_statistics.tail(1).to_string(index=False))\n",
        "\n",
        "    # Align games_df columns to match existing_statistics\n",
        "    games_df = games_df.reindex(columns=existing_statistics.columns)\n",
        "    combined_statistics = pd.concat([existing_statistics, games_df], ignore_index=True)\n",
        "\n",
        "    print(existing_statistics.columns.duplicated().any())\n",
        "    print(games_df.columns.duplicated().any())\n",
        "\n",
        "\n",
        "    # if 'mp' in combined_statistics.columns:\n",
        "    #     # Get the index of the 'mp' column\n",
        "    #     mp_col_index = combined_statistics.columns.get_loc('mp')\n",
        "    #     # Drop 'mp' and all columns after it\n",
        "    #     combined_statistics.drop(combined_statistics.columns[mp_col_index:], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "    combined_statistics.to_csv(os.path.join(SRC_DIR, file_name), index=False)\n",
        "    #os.remove('nba_games.csv')\n",
        "\n",
        "    # Copy any missing files from SRC_DIR to DST_DIR\n",
        "    #copy_missing_files(SRC_DIR, DST_DIR)\n",
        "\n",
        "def rename_duplicated_columns(df):\n",
        "    \"\"\"Rename duplicated columns by appending a suffix\"\"\"\n",
        "    cols = pd.Series(df.columns)\n",
        "    for dup in cols[cols.duplicated()].unique():\n",
        "        cols[cols[cols == dup].index.values.tolist()] = [dup + '_' + str(i) if i != 0 else dup for i in range(sum(cols == dup))]\n",
        "    df.columns = cols\n",
        "    return df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    process_nba_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zta5s13Y5Ui4",
        "outputId": "b5ef2636-b522-41b9-ef48-5e00e0a977a8"
      },
      "id": "zta5s13Y5Ui4",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-30\n",
            "Checking date: 2024-11-23, yesterday: 2024-11-30\n",
            "Checking date: 2024-11-23, yesterday: 2024-11-30\n",
            "Checking date: 2024-11-23, yesterday: 2024-11-30\n",
            "Checking date: 2024-11-23, yesterday: 2024-11-30\n",
            "Checking date: 2024-11-23, yesterday: 2024-11-30\n",
            "Checking date: 2024-11-23, yesterday: 2024-11-30\n",
            "Checking date: 2024-11-23, yesterday: 2024-11-30\n",
            "Checking date: 2024-11-30, yesterday: 2024-11-30\n",
            "Checking date: 2024-11-30, yesterday: 2024-11-30\n",
            "Checking date: 2024-11-30, yesterday: 2024-11-30\n",
            "Checking date: 2024-11-30, yesterday: 2024-11-30\n",
            "Checking date: 2024-11-30, yesterday: 2024-11-30\n",
            "   mp    mp   fg  fga   fg%   3p  3pa   3p%   ft  fta   ft%  orb  drb  trb  ast  stl  blk  tov   pf   pts  gmsc  +/-   ts%  efg%  3par   ftr  orb%  drb%  trb%  ast%  stl%  blk%  tov%  usg%  ortg  drtg  mp_max  mp_max  fg_max  fga_max  fg%_max  3p_max  3pa_max  3p%_max  ft_max  fta_max  ft%_max  orb_max  drb_max  trb_max  ast_max  stl_max  blk_max  tov_max  pf_max  pts_max  gmsc_max  +/-_max  ts%_max  efg%_max  3par_max  ftr_max  orb%_max  drb%_max  trb%_max  ast%_max  stl%_max  blk%_max  tov%_max  usg%_max  ortg_max  drtg_max team  total  home  index_opp  mp_opp  mp_opp  fg_opp  fga_opp  fg%_opp  3p_opp  3pa_opp  3p%_opp  ft_opp  fta_opp  ft%_opp  orb_opp  drb_opp  trb_opp  ast_opp  stl_opp  blk_opp  tov_opp  pf_opp  pts_opp  gmsc_opp  +/-_opp  ts%_opp  efg%_opp  3par_opp  ftr_opp  orb%_opp  drb%_opp  trb%_opp  ast%_opp  stl%_opp  blk%_opp  tov%_opp  usg%_opp  ortg_opp  drtg_opp  mp_max_opp  mp_max_opp  fg_max_opp  fga_max_opp  fg%_max_opp  3p_max_opp  3pa_max_opp  3p%_max_opp  ft_max_opp  fta_max_opp  ft%_max_opp  orb_max_opp  drb_max_opp  trb_max_opp  ast_max_opp  stl_max_opp  blk_max_opp  tov_max_opp  pf_max_opp  pts_max_opp  gmsc_max_opp  +/-_max_opp  ts%_max_opp  efg%_max_opp  3par_max_opp  ftr_max_opp  orb%_max_opp  drb%_max_opp  trb%_max_opp  ast%_max_opp  stl%_max_opp  blk%_max_opp  tov%_max_opp  usg%_max_opp  ortg_max_opp  drtg_max_opp team_opp  total_opp  home_opp season       date  won\n",
            "240.0 240.0 38.0 78.0 0.487 10.0 33.0 0.303 21.0 27.0 0.778 14.0 35.0 49.0 27.0  8.0  7.0 22.0 15.0 107.0   NaN  NaN 0.595 0.551 0.423 0.346  34.1  66.0  52.1  71.1   8.4  15.2  19.7 100.0 111.8 108.7     NaN     NaN     8.0     12.0    0.667     4.0      6.0    0.667     7.0      8.0      1.0      6.0     10.0     14.0      9.0      2.0      3.0      6.0     3.0     20.0      19.3     15.0    0.833     0.833       1.0      1.0      25.0      45.4      35.8      40.2       3.9      10.5      41.0      26.8     224.0     118.0  ATL    107     0          1   240.0   240.0    35.0     94.0    0.372    18.0     48.0    0.375    16.0     19.0    0.842     18.0     27.0     45.0     23.0     13.0      6.0     15.0    23.0    104.0       NaN      NaN    0.508     0.468     0.511    0.202      34.0      65.9      47.9      65.7      13.6      13.3      12.8     100.0     108.7     111.8         NaN         NaN        10.0         30.0          0.6         7.0         19.0        0.571         6.0          7.0          1.0          8.0          6.0          8.0          5.0          3.0          3.0          3.0         6.0         32.0          19.6         20.0        0.743         0.667         0.857          1.4          32.3          27.5          18.2          36.7           4.6          12.6          50.0          37.1         146.0         115.0      CHO        104         1   2025 2024-11-30 True\n",
            "nba_games_2024-12-01.csv\n",
            "Existing Statistics Duplicated Columns: Index([], dtype='object')\n",
            "Games DF Duplicated Columns: Index([], dtype='object')\n",
            "False\n",
            "False\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}