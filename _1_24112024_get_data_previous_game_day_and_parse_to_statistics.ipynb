{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alex-2911/Basketball-Projection/blob/main/_1_24112024_get_data_previous_game_day_and_parse_to_statistics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "!dpkg -i google-chrome-stable_current_amd64.deb\n",
        "!apt-get -f install -y\n",
        "\n",
        "!wget https://chromedriver.storage.googleapis.com/$(curl -sS https://chromedriver.storage.googleapis.com/LATEST_RELEASE)/chromedriver_linux64.zip\n",
        "!unzip chromedriver_linux64.zip\n",
        "!mv chromedriver /usr/bin/chromedriver\n",
        "!chmod +x /usr/bin/chromedriver\n"
      ],
      "metadata": {
        "id": "yKp2_f-fs52V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd500547-ddec-4ba4-e1fe-e317c68f77b0"
      },
      "id": "yKp2_f-fs52V",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-19 16:41:29--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "Resolving dl.google.com (dl.google.com)... 172.253.115.190, 172.253.115.136, 172.253.115.91, ...\n",
            "Connecting to dl.google.com (dl.google.com)|172.253.115.190|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 112770956 (108M) [application/x-debian-package]\n",
            "Saving to: ‘google-chrome-stable_current_amd64.deb’\n",
            "\n",
            "google-chrome-stabl 100%[===================>] 107.55M   316MB/s    in 0.3s    \n",
            "\n",
            "2024-12-19 16:41:29 (316 MB/s) - ‘google-chrome-stable_current_amd64.deb’ saved [112770956/112770956]\n",
            "\n",
            "Selecting previously unselected package google-chrome-stable.\n",
            "(Reading database ... 123635 files and directories currently installed.)\n",
            "Preparing to unpack google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (131.0.6778.204-1) ...\n",
            "\u001b[1mdpkg:\u001b[0m dependency problems prevent configuration of google-chrome-stable:\n",
            " google-chrome-stable depends on libvulkan1; however:\n",
            "  Package libvulkan1 is not installed.\n",
            "\n",
            "\u001b[1mdpkg:\u001b[0m error processing package google-chrome-stable (--install):\n",
            " dependency problems - leaving unconfigured\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Errors were encountered while processing:\n",
            " google-chrome-stable\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Correcting dependencies... Done\n",
            "The following additional packages will be installed:\n",
            "  libvulkan1 mesa-vulkan-drivers\n",
            "The following NEW packages will be installed:\n",
            "  libvulkan1 mesa-vulkan-drivers\n",
            "0 upgraded, 2 newly installed, 0 to remove and 49 not upgraded.\n",
            "1 not fully installed or removed.\n",
            "Need to get 10.9 MB of archives.\n",
            "After this operation, 51.3 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libvulkan1 amd64 1.3.204.1-2 [128 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 mesa-vulkan-drivers amd64 23.2.1-1ubuntu3.1~22.04.3 [10.7 MB]\n",
            "Fetched 10.9 MB in 1s (10.3 MB/s)\n",
            "Selecting previously unselected package libvulkan1:amd64.\n",
            "(Reading database ... 123752 files and directories currently installed.)\n",
            "Preparing to unpack .../libvulkan1_1.3.204.1-2_amd64.deb ...\n",
            "Unpacking libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Selecting previously unselected package mesa-vulkan-drivers:amd64.\n",
            "Preparing to unpack .../mesa-vulkan-drivers_23.2.1-1ubuntu3.1~22.04.3_amd64.deb ...\n",
            "Unpacking mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Setting up mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up google-chrome-stable (131.0.6778.204-1) ...\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/google-chrome (google-chrome) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "--2024-12-19 16:42:10--  https://chromedriver.storage.googleapis.com/114.0.5735.90/chromedriver_linux64.zip\n",
            "Resolving chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)... 142.251.179.207, 64.233.180.207, 172.253.115.207, ...\n",
            "Connecting to chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)|142.251.179.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7407250 (7.1M) [application/zip]\n",
            "Saving to: ‘chromedriver_linux64.zip’\n",
            "\n",
            "chromedriver_linux6 100%[===================>]   7.06M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2024-12-19 16:42:10 (131 MB/s) - ‘chromedriver_linux64.zip’ saved [7407250/7407250]\n",
            "\n",
            "Archive:  chromedriver_linux64.zip\n",
            "  inflating: chromedriver            \n",
            "  inflating: LICENSE.chromedriver    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import calendar\n",
        "import datetime\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "current_season = 2025\n",
        "\n",
        "#today = datetime.now()\n",
        "today = datetime.now() - timedelta(days=0)\n",
        "print(today)\n",
        "yesterday = datetime.now() - timedelta(days=1)\n",
        "\n",
        "\n",
        "import datetime\n",
        "#today_str_format = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "today_str_format = today.strftime(\"%Y-%m-%d\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfPBfd4FlJnI",
        "outputId": "12149670-7ae1-4075-e57e-de87ddf9dd6d"
      },
      "id": "wfPBfd4FlJnI",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-19 16:42:11.243799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get today's date\n",
        "# Determine the current and next month/year\n",
        "\n",
        "if today.day == 1:\n",
        "    current_month = today.month - 1\n",
        "\n",
        "    if current_month == 0:\n",
        "        current_month = 12\n",
        "        current_year = today.year - 1\n",
        "        last_month = 12\n",
        "        last_month_name = calendar.month_name[last_month].lower()\n",
        "    else:\n",
        "        current_year = today.year\n",
        "        last_month = current_month# - 1\n",
        "        last_month_name = calendar.month_name[last_month].lower()\n",
        "        print(last_month)\n",
        "else:\n",
        "    current_month = today.month\n",
        "    current_year = today.year\n",
        "    last_month = None  # Not used in this case"
      ],
      "metadata": {
        "id": "eRTDMt_elNQk"
      },
      "id": "eRTDMt_elNQk",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define base directory in Google Drive\n",
        "#DATA_DIR = os.path.join(\"/content/drive/My Drive\", \"NBA_Script\", \"2025\", \"Gathering_Data\", \"data\")\n",
        "#SRC_DIR = os.path.join(\"/content/drive/My Drive\", \"NBA_Script\", \"2025\", \"Gathering_Data\", \"Whole_Statistic\")\n",
        "\n",
        "# Define directories\n",
        "base_dir = \"/content/drive/My Drive/NBA_Script/2025/Gathering_Data\"\n",
        "STANDINGS_DIR = os.path.join(base_dir, f\"{current_season}_standings\")\n",
        "SCORES_DIR = os.path.join(base_dir, f\"{current_season}_scores\")\n",
        "SRC_DIR = os.path.join(base_dir, f\"Whole_Statistic\")\n",
        "\n",
        "\n",
        "# Define subdirectories\n",
        "#STANDINGS_DIR = os.path.join(DATA_DIR, f\"{current_season}_standings\")\n",
        "#SCORES_DIR = os.path.join(DATA_DIR, f\"{current_season}_scores\") #Fixed: Removed the extra 'S' and uncommented the line\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(STANDINGS_DIR, exist_ok=True)\n",
        "os.makedirs(SCORES_DIR, exist_ok=True)\n",
        "\n",
        "#print(f\"Data Directory: {DATA_DIR}\") #Fixed: DATA_DIR is commented out above and not defined, causing a NameError\n",
        "print(f\"Standings Directory: {STANDINGS_DIR}\")\n",
        "print(f\"Scores Directory: {SCORES_DIR}\")\n",
        "print(f\"Whole_Statistic Directory: {SRC_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz4ymPs5lkwQ",
        "outputId": "381929db-ebad-4a7c-a294-88bf802f5501"
      },
      "id": "Uz4ymPs5lkwQ",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Standings Directory: /content/drive/My Drive/NBA_Script/2025/Gathering_Data/2025_standings\n",
            "Scores Directory: /content/drive/My Drive/NBA_Script/2025/Gathering_Data/2025_scores\n",
            "Whole_Statistic Directory: /content/drive/My Drive/NBA_Script/2025/Gathering_Data/Whole_Statistic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_current_year_and_month():\n",
        "    \"\"\"\n",
        "    Returns the current year and month.\n",
        "    \"\"\"\n",
        "    today = datetime.now()\n",
        "    return today.year, today.month"
      ],
      "metadata": {
        "id": "lmXF02SGwIwP"
      },
      "id": "lmXF02SGwIwP",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium webdriver_manager\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.common.exceptions import TimeoutException, WebDriverException\n",
        "import os\n",
        "import logging\n",
        "import time\n",
        "\n",
        "# Configure logging\n",
        "# Initialize chrome_options before using it\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--disable-ipv6\")\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "def get_html(url, selector, sleep=5, retries=3, headless=True):\n",
        "    \"\"\"\n",
        "    Retrieves HTML content from a webpage using Selenium WebDriver.\n",
        "    \"\"\"\n",
        "    html = None\n",
        "    # Initialize driver to None outside the loop\n",
        "    driver = None\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            # WebDriver options\n",
        "            # chrome_options is now defined globally\n",
        "            if headless:\n",
        "                chrome_options.add_argument(\"--headless\")\n",
        "                chrome_options.add_argument(\"--no-sandbox\")\n",
        "                chrome_options.add_argument(\"--disable-dev-shm-usage\")  # Overcome limited resource issues\n",
        "\n",
        "            # Use ChromeDriverManager to manage the driver\n",
        "            service = Service(ChromeDriverManager().install())\n",
        "            driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "\n",
        "            driver.get(url)\n",
        "            time.sleep(sleep * (2 ** attempt))  # Exponential backoff\n",
        "            element = driver.find_element(By.CSS_SELECTOR, selector)\n",
        "            html = element.get_attribute(\"innerHTML\")\n",
        "\n",
        "            driver.quit() # Quit the driver after successful retrieval\n",
        "            break # Exit the retry loop if successful\n",
        "\n",
        "        except TimeoutException:\n",
        "            logging.warning(f\"Attempt {attempt + 1}: Timeout error on {url}. Retrying...\")\n",
        "            if driver is not None: # Now driver is defined before this line\n",
        "              driver.quit() #Quit the driver before retrying\n",
        "        except WebDriverException as e:\n",
        "            logging.error(f\"Webdriver error: {e}\")\n",
        "            if driver is not None: # Now driver is defined before this line\n",
        "              driver.quit() #Quit the driver if any WebDriverException occurs\n",
        "            break # Exit the loop if there's a WebDriverException\n",
        "\n",
        "    if html is None:\n",
        "        logging.error(f\"Failed to retrieve HTML content from {url} after {retries} attempts.\")\n",
        "\n",
        "    return html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb5obV5G91Kk",
        "outputId": "9ec0f988-a45f-404b-902b-8562dc298392"
      },
      "id": "pb5obV5G91Kk",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.27.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting webdriver_manager\n",
            "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.27.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.12.14)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from webdriver_manager) (2.32.3)\n",
            "Collecting python-dotenv (from webdriver_manager)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from webdriver_manager) (24.2)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (24.3.0)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver_manager) (3.4.0)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Downloading selenium-4.27.1-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
            "Downloading trio-0.27.0-py3-none-any.whl (481 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.7/481.7 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: sortedcontainers, wsproto, python-dotenv, outcome, webdriver_manager, trio, trio-websocket, selenium\n",
            "Successfully installed outcome-1.3.0.post0 python-dotenv-1.0.1 selenium-4.27.1 sortedcontainers-2.4.0 trio-0.27.0 trio-websocket-0.11.1 webdriver_manager-4.0.2 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_season_for_month(season, month, month_name, standings_dir, get_html_function):\n",
        "    \"\"\"\n",
        "    Scrapes NBA games data for a specific month and season from basketball-reference.com.\n",
        "\n",
        "    Args:\n",
        "        season (int): The NBA season year.\n",
        "        month (int): The month number (1-12).\n",
        "        month_name (str): The name of the month.\n",
        "        standings_dir (str): Directory path to save the scraped data.\n",
        "        get_html_function (function): Function to get HTML content from a URL.\n",
        "    \"\"\"\n",
        "    #current_year, current_month = get_current_year_and_month()\n",
        "\n",
        "    if season < current_year or (season == current_year and month < current_month):\n",
        "        logging.warning(\"Invalid year or month already passed.\")\n",
        "        return\n",
        "\n",
        "    logging.info(f\"Scraping games for: {season}, {month_name.title()}\")\n",
        "    url = f\"https://www.basketball-reference.com/leagues/NBA_{season}_games.html\"\n",
        "    selector = \"#content .filter\"\n",
        "    html_content = get_html_function(url, selector)\n",
        "\n",
        "    if not html_content:\n",
        "        logging.error(f\"Failed to retrieve data from {url}.\")\n",
        "        return\n",
        "\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    links = soup.find_all(\"a\", href=re.compile(\"/leagues/NBA_[0-9]{4}_games-[a-z]+\\.html\"))\n",
        "    standings_pages = [f\"https://www.basketball-reference.com{l['href']}\" for l in links]\n",
        "\n",
        "    for url in standings_pages:\n",
        "        save_path = os.path.join(standings_dir, url.split(\"/\")[-1])\n",
        "        if os.path.exists(save_path):\n",
        "            logging.info(f\"Path already exists: {save_path}\")\n",
        "            continue\n",
        "\n",
        "        if month_name in save_path.lower():\n",
        "            html = get_html_function(url, \"#all_schedule\")\n",
        "            #print(html)\n",
        "            if html:\n",
        "                try:\n",
        "                    with open(save_path, \"w+\", encoding='utf-8') as f:\n",
        "                        f.write(html)\n",
        "                    logging.info(f\"Data for {month_name.title()} saved.\")\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"Failed to save data for {month_name.title()}: {e}\")\n",
        "            else:\n",
        "                logging.error(f\"Failed to retrieve data for {month_name.title()} from {url}.\")\n",
        "\n",
        "# Usage example:\n",
        "# season = 2024\n",
        "# month = 1\n",
        "# standings_dir = \"path/to/standings_dir\"\n",
        "# scrape_monthly_games(season, month, standings_dir, get_html)\n"
      ],
      "metadata": {
        "id": "Wcqb-8kKmEXy"
      },
      "id": "Wcqb-8kKmEXy",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !apt-get update\n",
        "# !apt install chromium-chromedriver\n",
        "# !cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ],
      "metadata": {
        "id": "1tfvLR7_u6b8"
      },
      "id": "1tfvLR7_u6b8",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install selenium\n",
        "# from selenium import webdriver\n",
        "# from selenium.webdriver.chrome.options import Options\n",
        "# from selenium.webdriver.chrome.service import Service\n",
        "# from selenium.webdriver.common.by import By\n",
        "# from selenium.common.exceptions import TimeoutException, WebDriverException"
      ],
      "metadata": {
        "id": "phmsMFedvMdb"
      },
      "id": "phmsMFedvMdb",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def initialize_driver():\n",
        "#     chrome_options = Options()\n",
        "#     chrome_options.add_argument(\"--headless\")\n",
        "#     chrome_options.add_argument(\"--no-sandbox\")\n",
        "#     chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "#     service = Service(ChromeDriverManager().install())\n",
        "#     return webdriver.Chrome(service=service, options=chrome_options)\n"
      ],
      "metadata": {
        "id": "e4XiKTRKx2__"
      },
      "id": "e4XiKTRKx2__",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import calendar\n",
        "import logging\n",
        "from datetime import datetime\n",
        "\n",
        "#chromedriver_path = r\"D:\\1. Python\\3. chromedriver-win64\\chromedriver-win64\\chromedriver.exe\"\n",
        "\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Initialize variables\n",
        "current_season = 2025\n",
        "today = datetime.now()\n",
        "current_month = today.month\n",
        "current_year = today.year\n",
        "\n",
        "# Calculate next and last months\n",
        "next_month = current_month + 1 if current_month < 12 else 1\n",
        "next_year = current_year if next_month != 1 else current_year + 1\n",
        "last_month = current_month - 1 if current_month > 1 else 12\n",
        "last_year = current_year if last_month != 12 else current_year - 1\n",
        "\n",
        "# Month names\n",
        "current_month_name = calendar.month_name[current_month].lower()\n",
        "next_month_name = calendar.month_name[next_month].lower()\n",
        "last_month_name = calendar.month_name[last_month].lower()\n",
        "\n",
        "# Define directories\n",
        "#base_dir = \"/content/drive/My Drive/NBA_Script/2025/Gathering_Data\"\n",
        "#STANDINGS_DIR = os.path.join(base_dir, f\"{current_season}_standings\")\n",
        "#SCORES_DIR = os.path.join(base_dir, f\"{current_season}_scores\")\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(STANDINGS_DIR, exist_ok=True)\n",
        "os.makedirs(SCORES_DIR, exist_ok=True)\n",
        "\n",
        "# File removal logic\n",
        "file_to_remove = f\"NBA_{current_season}_games-{last_month_name}.html\"  # Use last_month_name (november)\n",
        "file_path = os.path.join(STANDINGS_DIR, file_to_remove)\n",
        "\n",
        "#Now file_to_remove and file_path are defined outside the if,\n",
        "#so they will be accessible in the try-except block\n",
        "if today.day == 1:  # Only delete previous month's file on the 1st\n",
        "\n",
        "    try:\n",
        "        if os.path.exists(file_path):\n",
        "            os.remove(file_path)\n",
        "            logging.info(f\"File {file_to_remove} has been removed.\")\n",
        "        else:\n",
        "            logging.info(f\"File {file_to_remove} does not exist.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An error occurred while removing {file_to_remove}: {e}\")\n",
        "\n",
        "try:\n",
        "    if os.path.exists(file_path):\n",
        "        os.remove(file_path)\n",
        "        logging.info(f\"File {file_to_remove} has been removed.\")\n",
        "    else:\n",
        "        logging.info(f\"File {file_to_remove} does not exist.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"An error occurred while removing {file_to_remove}: {e}\")\n",
        "\n",
        "# WebDriver initialization\n",
        "#driver = initialize_driver()\n",
        "\n",
        "try:\n",
        "    # Scrape games for the appropriate months\n",
        "    if today.day == 1:\n",
        "        scrape_season_for_month(current_season, last_month, last_month_name, STANDINGS_DIR, get_html)\n",
        "        scrape_season_for_month(current_season, next_month, next_month_name, STANDINGS_DIR, get_html)\n",
        "    else:\n",
        "        scrape_season_for_month(current_season, current_month, current_month_name, STANDINGS_DIR, get_html)\n",
        "\n",
        "    # Example of processing game data (uncomment when functions are defined)\n",
        "    # standings_files = os.listdir(STANDINGS_DIR)\n",
        "    # for f in standings_files:\n",
        "    #     if str(current_year) in f:\n",
        "    #         filepath = os.path.join(STANDINGS_DIR, f)\n",
        "    #         scrape_game(filepath, SCORES_DIR, driver)\n",
        "\n",
        "finally:\n",
        "    #driver.quit()\n",
        "    logging.info(\"Driver session closed.\")\n"
      ],
      "metadata": {
        "id": "AKpeAmbkmKTs"
      },
      "id": "AKpeAmbkmKTs",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "\n",
        "def scrape_game(standings_file, scores_dir, get_html_function):\n",
        "    \"\"\"\n",
        "    Scrapes box scores for NBA games from the provided standings file.\n",
        "\n",
        "    Args:\n",
        "        standings_file (str): Path to the file containing the standings data.\n",
        "        scores_dir (str): Directory path to save the scraped box scores.\n",
        "        get_html_function (function): Function to get HTML content from a URL.\n",
        "    \"\"\"\n",
        "    # Calculate the date of yesterday\n",
        "    #yesterday = datetime.now() - timedelta(days=1)\n",
        "    yesterday_date = yesterday.strftime(\"%Y%m%d\")  # Format: YYYYMMDD\n",
        "\n",
        "    with open(standings_file, 'r',encoding='utf-8') as f:\n",
        "        html = f.read()\n",
        "\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    links = soup.find_all(\"a\")\n",
        "    hrefs = [l.get('href') for l in links]\n",
        "    box_scores = [f\"https://www.basketball-reference.com{l}\" for l in hrefs if l and \"boxscore\" in l and '.html' in l]\n",
        "\n",
        "    filtered_urls = [url for url in box_scores if yesterday_date in url]\n",
        "\n",
        "    for url in filtered_urls:\n",
        "        save_path = os.path.join(scores_dir, url.split(\"/\")[-1])\n",
        "\n",
        "        if os.path.exists(save_path):\n",
        "            continue\n",
        "\n",
        "        html = get_html_function(url, \"#content\")\n",
        "\n",
        "        if not html:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            with open(save_path, \"wb+\") as f:\n",
        "                f.write(html.encode(\"utf-8\"))\n",
        "            print(f\"Box score saved: {save_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to save box score: {e}\")\n"
      ],
      "metadata": {
        "id": "Y15qWqeU27xK"
      },
      "id": "Y15qWqeU27xK",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_standings_files(standings_dir, current_season):\n",
        "    \"\"\"\n",
        "    Process standings files for a specific season.\n",
        "\n",
        "    Args:\n",
        "        standings_dir (str): Directory containing standings files.\n",
        "        current_season (int): The current NBA season year.\n",
        "    \"\"\"\n",
        "    standings_files = os.listdir(standings_dir)\n",
        "    print(standings_files)\n",
        "\n",
        "    # Filter files for the current season\n",
        "    files = [s for s in standings_files if str(current_season) in s]\n",
        "\n",
        "    for f in files:\n",
        "        filepath = os.path.join(standings_dir, f)\n",
        "        print(filepath)\n",
        "\n",
        "        scrape_game(filepath, SCORES_DIR, get_html)  # Assuming scrape_game is implemented\n",
        "\n",
        "# Call the function with your STANDINGS_DIR and current_season\n",
        "process_standings_files(STANDINGS_DIR, current_season)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7yt3cHz2q13",
        "outputId": "6336ea23-32e7-43d1-d2bf-6838a63f5d4e"
      },
      "id": "S7yt3cHz2q13",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NBA_2025_games-october.html', 'NBA_2025_games-january.html', 'NBA_2025_games-december.html']\n",
            "/content/drive/My Drive/NBA_Script/2025/Gathering_Data/2025_standings/NBA_2025_games-october.html\n",
            "/content/drive/My Drive/NBA_Script/2025/Gathering_Data/2025_standings/NBA_2025_games-january.html\n",
            "/content/drive/My Drive/NBA_Script/2025/Gathering_Data/2025_standings/NBA_2025_games-december.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def get_first_game_date(standings_file):\n",
        "    \"\"\"\n",
        "    Extract the date of the first game day from the standings file.\n",
        "\n",
        "    Args:\n",
        "        standings_file (str): Path to the standings HTML file.\n",
        "\n",
        "    Returns:\n",
        "        str: The date of the first game, formatted as 'Day, Month Date, Year'.\n",
        "    \"\"\"\n",
        "    with open(standings_file, 'r', encoding='utf-8') as f:\n",
        "        html = f.read()\n",
        "\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "    # Find the first game date in the standings table\n",
        "    table = soup.find(\"table\", {\"id\": \"schedule\"})\n",
        "\n",
        "    if not table:\n",
        "        print(f\"No schedule table found in {standings_file}.\")\n",
        "        return None\n",
        "\n",
        "    # Look for the first non-header row (actual game data)\n",
        "    first_game_row = table.find_all(\"tr\")[1]  # Skip the header row and take the first game row\n",
        "    if first_game_row:\n",
        "        game_date_tag = first_game_row.find(\"th\", {\"data-stat\": \"date_game\"})\n",
        "        if game_date_tag:\n",
        "            return game_date_tag.text.strip()  # Returns the date of the first game\n",
        "\n",
        "    return None\n",
        "\n",
        "# Example usage\n",
        "standings_file =  os.path.join(STANDINGS_DIR, 'NBA_2025_games-october.html')  # Replace with the actual path to your file\n",
        "\n",
        "first_game_date_str = get_first_game_date(standings_file)\n",
        "#if first_game_date_str:\n",
        "#    print(f\"The first game is scheduled on: {first_game_date_str}\")\n",
        "#else:\n",
        "#    print(\"No game dates found in the file.\")\n"
      ],
      "metadata": {
        "id": "VDYQFIqj36pY"
      },
      "id": "VDYQFIqj36pY",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import logging\n",
        "from io import StringIO\n",
        "import numpy as np\n",
        "\n",
        "MAX_DAYS_BACK = 150  # Configurable range for searching files\n",
        "\n",
        "# Constants\n",
        "#SCORE_DIR = \"data/2025_scores\"\n",
        "#SRC_DIR = r'D:\\1. Python\\1. NBA Script\\2025\\Gathering_Data\\Whole_Statistic'\n",
        "#DST_DIR = r'D:\\_Laufwerk C\\11. Sorare\\NBA\\2025\\Gathering_Data\\Whole_Statistic'\n",
        "\n",
        "# Assume first_game_date is already defined in your code\n",
        "\n",
        "first_game_date = datetime.datetime.strptime(first_game_date_str, \"%a, %b %d, %Y\").date()\n",
        "\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Check if the current date is before the season start date\n",
        "today = datetime.date.today()\n",
        "if today < first_game_date:\n",
        "    logging.info(f\"Current date ({today}) is before the NBA season start date ({first_game_date}). Script will not run.\")\n",
        "    exit()\n",
        "\n",
        "# If the script reaches here, it means the season has started, and we can proceed\n",
        "\n",
        "\n",
        "# Function to check if file exists\n",
        "def file_exists(date_str):\n",
        "    \"\"\"Check if a specific file exists based on the date string.\"\"\"\n",
        "    filename = f\"nba_games_{date_str}.csv\"\n",
        "    return os.path.isfile(os.path.join(SRC_DIR, filename))\n",
        "\n",
        "# Function to find the most recent file\n",
        "def find_most_recent_file(max_days=MAX_DAYS_BACK):\n",
        "    \"\"\"Find the most recent file within a specified number of days.\"\"\"\n",
        "    days_back = 1\n",
        "    while days_back <= max_days:\n",
        "        most_recent_date = (today - datetime.timedelta(days=days_back)).strftime(\"%Y-%m-%d\")\n",
        "        if file_exists(most_recent_date):\n",
        "            logging.info(f\"The file for {most_recent_date} exists.\")\n",
        "            return most_recent_date\n",
        "        else:\n",
        "            days_back += 1\n",
        "\n",
        "    logging.warning(\"No file found within the specified range.\")\n",
        "    return None\n",
        "\n",
        "# Main script execution\n",
        "try:\n",
        "    most_recent_date = find_most_recent_file()\n",
        "\n",
        "    if most_recent_date:\n",
        "        # Proceed with processing the found file\n",
        "        # Add your processing logic here\n",
        "        logging.info(f\"Processing file for {most_recent_date}\")\n",
        "    else:\n",
        "        # Handle the case when no file is found\n",
        "        logging.warning(\"No recent data available to process.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    logging.error(\"File or directory not found.\")\n",
        "except IOError:\n",
        "    logging.error(\"Error accessing file.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "\n",
        "# #########################################################################################################################\n",
        "# # CHECK FIRST IF THE SEASON HAS BEGUN AND THE DATA FROM PREVIOUS GAME DAY IS ACTUALLY AVAILABLE#\n",
        "# ##############################################################################################################"
      ],
      "metadata": {
        "id": "JQXUxrCh4U7U"
      },
      "id": "JQXUxrCh4U7U",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "today = datetime.date.today()\n",
        "if today < first_game_date:\n",
        "    logging.info(f\"Current date ({today}) is before the NBA season start date ({first_game_date}). Script will not run.\")\n",
        "    exit()\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Constants\n",
        "#SRC_DIR = r'D:\\1. Python\\1. NBA Script\\2025\\Gathering_Data\\Whole_Statistic'\n",
        "#SCORE_DIR = r'path_to_score_data'  # Define the path to score data\n",
        "\n",
        "# Functions\n",
        "def parse_html(box_score):\n",
        "    \"\"\"Parse HTML content from a box score file.\"\"\"\n",
        "    try:\n",
        "        with open(box_score, encoding='utf-8') as f:\n",
        "            html = f.read()\n",
        "        soup = BeautifulSoup(html, 'html.parser')\n",
        "        [s.decompose() for s in soup.select(\"tr.over_header, tr.thead\")]\n",
        "        return soup\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error parsing HTML for {box_score}: {e}\")\n",
        "        return None\n",
        "\n",
        "def read_season_info(soup):\n",
        "    \"\"\"Extract season information from the soup object.\"\"\"\n",
        "    nav = soup.select(\"#bottom_nav_container\")[0]\n",
        "    hrefs = [a[\"href\"] for a in nav.find_all('a')]\n",
        "    return os.path.basename(hrefs[1]).split(\"_\")[0]\n",
        "\n",
        "def read_line_score(soup):\n",
        "    \"\"\"Read line score from the soup object.\"\"\"\n",
        "    line_score = pd.read_html(StringIO(str(soup)), attrs={'id': 'line_score'})[0]\n",
        "    cols = list(line_score.columns)\n",
        "    cols[0] = \"team\"\n",
        "    cols[-1] = \"total\"\n",
        "    line_score.columns = cols\n",
        "    line_score = line_score[[\"team\", \"total\"]]\n",
        "    return line_score\n",
        "\n",
        "def read_stats(soup, team, stat):\n",
        "    \"\"\"Read team statistics from the soup object.\"\"\"\n",
        "    df = pd.read_html(StringIO(str(soup)), attrs={'id': f'box-{team}-game-{stat}'}, index_col=0)[0]\n",
        "    return df.apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "def copy_missing_files(src_dir, dst_dir):\n",
        "    \"\"\"Copy missing files from source to destination directory.\"\"\"\n",
        "    src_files = set(os.listdir(src_dir))\n",
        "    dst_files = set(os.listdir(dst_dir))\n",
        "    diff = src_files - dst_files\n",
        "\n",
        "    for file_name in diff:\n",
        "        if not file_name.startswith('.') and not file_name.endswith('.ipynb'):\n",
        "            shutil.copy2(os.path.join(src_dir, file_name), dst_dir)\n",
        "            logging.info(f'File {file_name} copied successfully')"
      ],
      "metadata": {
        "id": "y7zvj_Db6cjD"
      },
      "id": "y7zvj_Db6cjD",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_nba_data():\n",
        "    \"\"\"Main function to process NBA data.\"\"\"\n",
        "    # Ensure necessary variables are defined\n",
        "    today = datetime.date.today()\n",
        "    yesterday = today - datetime.timedelta(days=1)\n",
        "    most_recent_date = yesterday.strftime(\"%Y-%m-%d\")\n",
        "    SCORE_DIR = r'path_to_score_data'  # Update with the actual path to your score data\n",
        "    DST_DIR = r'path_to_destination_directory'  # Update with the actual destination directory\n",
        "\n",
        "    last_file_date = most_recent_date\n",
        "    print(f\"Processing data for date: {last_file_date}\")\n",
        "\n",
        "    filename = f\"nba_games_{last_file_date}.csv\"\n",
        "\n",
        "    try:\n",
        "        existing_statistics = pd.read_csv(os.path.join(SRC_DIR, filename))\n",
        "    except FileNotFoundError:\n",
        "        logging.error(f\"File {filename} not found in {SRC_DIR}.\")\n",
        "        return\n",
        "\n",
        "    base_cols = None\n",
        "    games = []\n",
        "\n",
        "    box_scores = [\n",
        "        os.path.join(SCORE_DIR, f)\n",
        "        for f in os.listdir(SCORE_DIR)\n",
        "        if f.endswith(\".html\")\n",
        "    ]\n",
        "\n",
        "    if not box_scores:\n",
        "        logging.error(f\"No box score files found in directory: {SCORE_DIR}\")\n",
        "        return\n",
        "\n",
        "    for box_score in box_scores:\n",
        "        try:\n",
        "            date_str = os.path.basename(box_score)[:8]\n",
        "            date = pd.to_datetime(date_str, format=\"%Y%m%d\").date()\n",
        "            if date < yesterday:\n",
        "                continue\n",
        "\n",
        "            soup = parse_html(box_score)\n",
        "            if soup is None:\n",
        "                raise ValueError(f\"Parsing failed for {box_score}\")\n",
        "\n",
        "            line_score = read_line_score(soup)\n",
        "            if line_score.empty:\n",
        "                raise ValueError(f\"Line score is empty for {box_score}\")\n",
        "\n",
        "            teams = list(line_score[\"team\"])\n",
        "            if not teams:\n",
        "                raise ValueError(f\"No teams found in line score for {box_score}\")\n",
        "\n",
        "            summaries = []\n",
        "\n",
        "            for team in teams:\n",
        "                basic = read_stats(soup, team, \"basic\")\n",
        "                advanced = read_stats(soup, team, \"advanced\")\n",
        "\n",
        "                if basic.empty or advanced.empty:\n",
        "                    logging.warning(f\"Empty stats for team {team} in {box_score}\")\n",
        "                    continue\n",
        "\n",
        "                totals = pd.concat([basic.iloc[-1], advanced.iloc[-1]])\n",
        "                totals.index = totals.index.str.lower()\n",
        "\n",
        "                maxes = pd.concat([basic.iloc[:-1].max(), advanced.iloc[:-1].max()])\n",
        "                maxes.index = maxes.index.str.lower() + \"_max\"\n",
        "\n",
        "                summary = pd.concat([totals, maxes])\n",
        "                if base_cols is None:\n",
        "                    base_cols = [\n",
        "                        b\n",
        "                        for b in summary.index.drop_duplicates(keep=\"first\")\n",
        "                        if \"bpm\" not in b\n",
        "                    ]\n",
        "                summary = summary[base_cols]\n",
        "                summaries.append(summary)\n",
        "\n",
        "            if not summaries:\n",
        "                logging.warning(f\"No summaries generated for {box_score}\")\n",
        "                continue\n",
        "\n",
        "            summary = pd.concat(summaries, axis=1).T\n",
        "            game = pd.concat([summary, line_score], axis=1)\n",
        "            game[\"home\"] = [0, 1]\n",
        "\n",
        "            game_opp = game.iloc[::-1].reset_index(drop=True)\n",
        "            game_opp.columns += \"_opp\"\n",
        "\n",
        "            full_game = pd.concat([game, game_opp], axis=1)\n",
        "\n",
        "            full_game[\"season\"] = read_season_info(soup)\n",
        "            full_game[\"date\"] = pd.to_datetime(date_str, format=\"%Y%m%d\")\n",
        "            full_game[\"won\"] = full_game[\"total\"] > full_game[\"total_opp\"]\n",
        "            games.append(full_game)\n",
        "\n",
        "            if len(games) % 10 == 0:\n",
        "                logging.info(f\"{len(games)} games processed successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error processing {box_score}: {e}\")\n",
        "\n",
        "    if not games:\n",
        "        logging.error(\"No valid games were processed. Check input data and parsing logic.\")\n",
        "        return\n",
        "\n",
        "    games_df = pd.concat(games, ignore_index=True)\n",
        "    print(\"Sample of processed games data:\")\n",
        "    print(games_df.head(1).to_string(index=False))\n",
        "\n",
        "    # Ensure there are no duplicated columns in games_df\n",
        "    games_df = rename_duplicated_columns(games_df)\n",
        "\n",
        "    # Reindex games_df to match the columns of existing_statistics\n",
        "    games_df = games_df.reindex(columns=existing_statistics.columns)\n",
        "\n",
        "    # Check and print duplicated columns for diagnosis\n",
        "    print(\n",
        "        \"Existing Statistics Duplicated Columns:\",\n",
        "        existing_statistics.columns[existing_statistics.columns.duplicated()],\n",
        "    )\n",
        "    print(\n",
        "        \"Games DF Duplicated Columns:\",\n",
        "        games_df.columns[games_df.columns.duplicated()],\n",
        "    )\n",
        "\n",
        "    existing_statistics.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Combine existing statistics with new games data\n",
        "    combined_statistics = pd.concat(\n",
        "        [existing_statistics, games_df], ignore_index=True\n",
        "    )\n",
        "\n",
        "    combined_statistics.to_csv(os.path.join(SRC_DIR, filename), index=False)\n",
        "    logging.info(f\"Combined statistics saved to {os.path.join(SRC_DIR, filename)}\")\n",
        "\n",
        "    # Copy any missing files from SRC_DIR to DST_DIR\n",
        "    copy_missing_files(SRC_DIR, DST_DIR)\n"
      ],
      "metadata": {
        "id": "zta5s13Y5Ui4"
      },
      "id": "zta5s13Y5Ui4",
      "execution_count": 17,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}